#' Compute Cohen's f-squared for One or Two Linear Models
#'
#' This takes one or two linear models and returns the value of f^2 as outlined in Cohen (1988). f^2 is a measure of the *local* effect size of a model. By comparing two models using `cohen_f2(model0,model1)` the researcher can determine if the *effect* of including the additional predictor variables in model1 is significant enough to justify the increased complexity of the model.
#'
#' Cohen suggested the following cut off values for f^2
#'
#' f^2 >= 0.02 : Small
#' f^2 >= 0.15 : Moderate
#' f^2 >= 0.35 : Large
#'
#' @param baseModel a model generated by a call to lm()
#' @param comparisonModel a more complex model generated by a call to lm()
#'
#' @return The value of f^2
#' @export
#'
#' @examples
#'
#' ## Generate some test data where y = x^2 + noise
#' df <- tibble::tibble(x = seq(1, 10, length.out = 100), y = x^2 + rnorm(length(x)))
#'
#' ## Create two simple linear models
#' model0 <- lm(y ~ x, data = df)
#' model1 <- lm(y ~ x + I(x^2), data = df)
#'
#' ## Check the fit of each model to the data
#' cohen_f2(model0)
#' cohen_f2(model1)
#'
#' ## Check if model1 is a better fit for the data than model0
#' cohen_f2(model0, model1)
#'
cohen_f2 <- function(baseModel, comparisonModel) {
  stopifnot(is.list(baseModel), exists("model", where = baseModel))

  R2 <- summary(baseModel)$r.squared

  if (missing(comparisonModel)) {
    f_2 <- R2 / (1 - R2)
  } else {
    stopifnot(is.list(comparisonModel), exists("model", where = comparisonModel))

    R2C <- summary(comparisonModel)$r.squared

    f_2 <- (R2C - R2) / (1 - R2C)
  }

  return(f_2)
}
